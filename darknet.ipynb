{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-18T08:00:51.740429400Z",
     "start_time": "2023-10-18T08:00:51.728051900Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "class EmptyLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "class DetectionLayer(nn.Module):\n",
    "    def __init__(self, anchors):\n",
    "        super().__init__()\n",
    "        self.anchors = anchors"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T08:00:51.759936100Z",
     "start_time": "2023-10-18T08:00:51.745537200Z"
    }
   },
   "id": "729234750bd9511d"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def read_cfg(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    lines: list[str] = list(map(lambda x: x.strip(), lines))\n",
    "    lines = [line for line in lines if len(line) > 0 and line[0] != '#']\n",
    "\n",
    "    blocks = []\n",
    "    for line in lines:\n",
    "        if line.startswith('['):\n",
    "            blocks.append({})\n",
    "            blocks[-1]['type'] = line.strip('[]')\n",
    "        else:\n",
    "            key, value = map(lambda x: x.strip(), line.split('='))\n",
    "\n",
    "            try:\n",
    "                value = float(value)\n",
    "            except Exception:\n",
    "                pass\n",
    "            else:\n",
    "                value = int(value) if float(value).is_integer() else float(value)\n",
    "\n",
    "            blocks[-1][key] = value\n",
    "\n",
    "    return blocks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T08:00:51.782398500Z",
     "start_time": "2023-10-18T08:00:51.759936100Z"
    }
   },
   "id": "317d4dec83409fd9"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def create_modules(blocks: list[dict[str, str | int | float]]):\n",
    "    net = blocks[0]\n",
    "    del blocks[0]\n",
    "\n",
    "    prev_filters = 3\n",
    "    filters = 3\n",
    "\n",
    "    out_filters = []\n",
    "\n",
    "    modules = nn.ModuleList()\n",
    "    for i, block in enumerate(blocks):\n",
    "        module = nn.Sequential()\n",
    "        block_type = block['type']\n",
    "\n",
    "        if block_type == 'convolutional':\n",
    "            batch_normalize = block.get('batch_normalize', 0)\n",
    "            is_bias = not batch_normalize\n",
    "            filters = block['filters']\n",
    "            kernel_size = block['size']\n",
    "            stride = block['stride']\n",
    "            padding = block['pad']\n",
    "            activation = block['activation']\n",
    "\n",
    "            module.add_module(\n",
    "                f\"conv_{i}\",\n",
    "                nn.Conv2d(prev_filters, filters, kernel_size, stride, padding, bias=is_bias)\n",
    "            )\n",
    "\n",
    "            if batch_normalize:\n",
    "                bn = nn.BatchNorm2d(filters)\n",
    "                module.add_module(f\"batch_norm_{i}\", bn)\n",
    "\n",
    "            if activation == 'leaky':\n",
    "                activation = nn.LeakyReLU(0.1, inplace=True)\n",
    "                module.add_module(f\"leaky_{i}\", activation)\n",
    "        elif block_type == 'upsample':\n",
    "            stride = block['stride']\n",
    "\n",
    "            module.add_module(\n",
    "                f\"upsample_{i}\",\n",
    "                nn.Upsample(scale_factor=stride, mode='bilinear')\n",
    "            )\n",
    "        elif block_type == 'route':\n",
    "            start, end = block['layers'], 0\n",
    "            if isinstance(start, str):\n",
    "                _split = map(int, start.split(','))\n",
    "                start, end = _split\n",
    "\n",
    "            if start > 0:\n",
    "                start -= i\n",
    "            if end > 0:\n",
    "                end -= i\n",
    "\n",
    "            module.add_module(f\"route_{i}\", EmptyLayer())\n",
    "\n",
    "            if end < 0:\n",
    "                filters = out_filters[i + start] + out_filters[i + end]\n",
    "            else:\n",
    "                filters = out_filters[i + start]\n",
    "        elif block_type == 'shortcut':\n",
    "            module.add_module(\n",
    "                f\"shortcut_{i}\", EmptyLayer()\n",
    "            )\n",
    "        elif block_type == 'yolo':\n",
    "            mask = list(map(int, block['mask'].split(',')))\n",
    "            anchors = list(map(int, block['anchors'].split(',')))\n",
    "            anchors = [(anchors[i], anchors[i + 1]) for i in range(0, len(anchors), 2)]\n",
    "            anchors = [anchors[i] for i in mask]\n",
    "            detection = DetectionLayer(anchors)\n",
    "\n",
    "            module.add_module(f\"detection_{i}\", detection)\n",
    "\n",
    "        modules.append(module)\n",
    "        prev_filters = filters\n",
    "        out_filters.append(prev_filters)\n",
    "\n",
    "    return net, modules"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T08:00:51.823936600Z",
     "start_time": "2023-10-18T08:00:51.805454800Z"
    }
   },
   "id": "43044f1ff07e43f3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict_transform(prediction, input_dim, anchors, num_classes, device = torch.device('cpu')):\n",
    "    batch_size = prediction.size(0)\n",
    "    stride = input_dim // prediction.size(2)\n",
    "    grid_size = input_dim // stride\n",
    "    bbox_attrs = 5 + num_classes\n",
    "    num_anchors = len(anchors)\n",
    "    \n",
    "    prediction = prediction.view(batch_size, bbox_attrs * num_anchors, grid_size * grid_size)\n",
    "    prediction = prediction.transpose(1, 2).contiguous()\n",
    "    prediction = prediction.view(batch_size, grid_size * grid_size * num_anchors, bbox_attrs)\n",
    "    \n",
    "    anchors = [(a[0] / stride, a[1] / stride) for a in anchors]\n",
    "    \n",
    "    prediction[..., ..., 0] = torch.sigmoid(prediction[..., ..., 0])\n",
    "    prediction[..., ..., 1] = torch.sigmoid(prediction[..., ..., 1])\n",
    "    prediction[..., ..., 4] = torch.sigmoid(prediction[..., ..., 4])\n",
    "    \n",
    "    grid = np.arange(grid_size)\n",
    "    x, y = np.meshgrid(grid, grid)\n",
    "    \n",
    "    x_offset = torch.FloatTensor(x).view(-1, 1).device(device)\n",
    "    y_offset = torch.FloatTensor(y).view(-1, 1).device(device)\n",
    "    x_y_offset = torch.cat((x_offset, y_offset), 1).repeat(1, num_anchors).view(-1, 2).unsqueeze(0)\n",
    "    \n",
    "    prediction[..., ..., :2] += x_y_offset\n",
    "    \n",
    "    anchors = torch.FloatTensor(anchors).device(device)\n",
    "    anchors = anchors.repeat(grid_size * grid_size, 1).unsqueeze(0)\n",
    "    \n",
    "    prediction[..., ..., 2:4] = torch.exp(prediction[..., ..., 2:4]) * anchors\n",
    "    prediction[..., ..., 5:5+num_classes] = torch.sigmoid(prediction[..., ..., 5:5+num_classes])\n",
    "    \n",
    "    prediction[..., ..., :4] *= stride\n",
    "    \n",
    "    return prediction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44d3bef461abbe23"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "({'type': 'net',\n  'batch': 64,\n  'subdivisions': 16,\n  'width': 608,\n  'height': 608,\n  'channels': 3,\n  'momentum': 0.9,\n  'decay': 0.0005,\n  'angle': 0,\n  'saturation': 1.5,\n  'exposure': 1.5,\n  'hue': 0.1,\n  'learning_rate': 0.001,\n  'burn_in': 1000,\n  'max_batches': 500200,\n  'policy': 'steps',\n  'steps': '400000,450000',\n  'scales': '.1,.1'},\n ModuleList(\n   (0): Sequential(\n     (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_0): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (1): Sequential(\n     (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n     (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_1): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (2): Sequential(\n     (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_2): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (3): Sequential(\n     (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_3): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (4): Sequential(\n     (shortcut_4): EmptyLayer()\n   )\n   (5): Sequential(\n     (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n     (batch_norm_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_5): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (6): Sequential(\n     (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_6): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (7): Sequential(\n     (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_7): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (8): Sequential(\n     (shortcut_8): EmptyLayer()\n   )\n   (9): Sequential(\n     (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_9): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (10): Sequential(\n     (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_10): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (11): Sequential(\n     (shortcut_11): EmptyLayer()\n   )\n   (12): Sequential(\n     (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n     (batch_norm_12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_12): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (13): Sequential(\n     (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_13): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (14): Sequential(\n     (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_14): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (15): Sequential(\n     (shortcut_15): EmptyLayer()\n   )\n   (16): Sequential(\n     (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_16): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (17): Sequential(\n     (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_17): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (18): Sequential(\n     (shortcut_18): EmptyLayer()\n   )\n   (19): Sequential(\n     (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_19): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (20): Sequential(\n     (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_20): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (21): Sequential(\n     (shortcut_21): EmptyLayer()\n   )\n   (22): Sequential(\n     (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_22): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (23): Sequential(\n     (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_23): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (24): Sequential(\n     (shortcut_24): EmptyLayer()\n   )\n   (25): Sequential(\n     (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_25): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (26): Sequential(\n     (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_26): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (27): Sequential(\n     (shortcut_27): EmptyLayer()\n   )\n   (28): Sequential(\n     (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_28): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (29): Sequential(\n     (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_29): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (30): Sequential(\n     (shortcut_30): EmptyLayer()\n   )\n   (31): Sequential(\n     (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_31): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (32): Sequential(\n     (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_32): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (33): Sequential(\n     (shortcut_33): EmptyLayer()\n   )\n   (34): Sequential(\n     (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_34): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (35): Sequential(\n     (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_35): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (36): Sequential(\n     (shortcut_36): EmptyLayer()\n   )\n   (37): Sequential(\n     (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n     (batch_norm_37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_37): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (38): Sequential(\n     (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_38): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (39): Sequential(\n     (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_39): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (40): Sequential(\n     (shortcut_40): EmptyLayer()\n   )\n   (41): Sequential(\n     (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_41): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (42): Sequential(\n     (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_42): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (43): Sequential(\n     (shortcut_43): EmptyLayer()\n   )\n   (44): Sequential(\n     (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_44): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (45): Sequential(\n     (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_45): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (46): Sequential(\n     (shortcut_46): EmptyLayer()\n   )\n   (47): Sequential(\n     (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_47): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (48): Sequential(\n     (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_48): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (49): Sequential(\n     (shortcut_49): EmptyLayer()\n   )\n   (50): Sequential(\n     (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_50): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (51): Sequential(\n     (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_51): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (52): Sequential(\n     (shortcut_52): EmptyLayer()\n   )\n   (53): Sequential(\n     (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_53): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (54): Sequential(\n     (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_54): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (55): Sequential(\n     (shortcut_55): EmptyLayer()\n   )\n   (56): Sequential(\n     (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_56): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (57): Sequential(\n     (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_57): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (58): Sequential(\n     (shortcut_58): EmptyLayer()\n   )\n   (59): Sequential(\n     (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_59): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (60): Sequential(\n     (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_60): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (61): Sequential(\n     (shortcut_61): EmptyLayer()\n   )\n   (62): Sequential(\n     (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n     (batch_norm_62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_62): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (63): Sequential(\n     (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_63): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (64): Sequential(\n     (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_64): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (65): Sequential(\n     (shortcut_65): EmptyLayer()\n   )\n   (66): Sequential(\n     (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_66): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (67): Sequential(\n     (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_67): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (68): Sequential(\n     (shortcut_68): EmptyLayer()\n   )\n   (69): Sequential(\n     (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_69): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (70): Sequential(\n     (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_70): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (71): Sequential(\n     (shortcut_71): EmptyLayer()\n   )\n   (72): Sequential(\n     (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_72): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (73): Sequential(\n     (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_73): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (74): Sequential(\n     (shortcut_74): EmptyLayer()\n   )\n   (75): Sequential(\n     (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_75): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (76): Sequential(\n     (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_76): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (77): Sequential(\n     (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_77): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (78): Sequential(\n     (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_78): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (79): Sequential(\n     (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_79): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (80): Sequential(\n     (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_80): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (81): Sequential(\n     (conv_81): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n   )\n   (82): Sequential(\n     (detection_82): DetectionLayer()\n   )\n   (83): Sequential(\n     (route_83): EmptyLayer()\n   )\n   (84): Sequential(\n     (conv_84): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_84): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_84): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (85): Sequential(\n     (upsample_85): Upsample(scale_factor=2.0, mode='bilinear')\n   )\n   (86): Sequential(\n     (route_86): EmptyLayer()\n   )\n   (87): Sequential(\n     (conv_87): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_87): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_87): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (88): Sequential(\n     (conv_88): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_88): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_88): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (89): Sequential(\n     (conv_89): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_89): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_89): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (90): Sequential(\n     (conv_90): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_90): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_90): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (91): Sequential(\n     (conv_91): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_91): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_91): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (92): Sequential(\n     (conv_92): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_92): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_92): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (93): Sequential(\n     (conv_93): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n   )\n   (94): Sequential(\n     (detection_94): DetectionLayer()\n   )\n   (95): Sequential(\n     (route_95): EmptyLayer()\n   )\n   (96): Sequential(\n     (conv_96): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_96): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_96): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (97): Sequential(\n     (upsample_97): Upsample(scale_factor=2.0, mode='bilinear')\n   )\n   (98): Sequential(\n     (route_98): EmptyLayer()\n   )\n   (99): Sequential(\n     (conv_99): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_99): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_99): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (100): Sequential(\n     (conv_100): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_100): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_100): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (101): Sequential(\n     (conv_101): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_101): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_101): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (102): Sequential(\n     (conv_102): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_102): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_102): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (103): Sequential(\n     (conv_103): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_103): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_103): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (104): Sequential(\n     (conv_104): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (batch_norm_104): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (leaky_104): LeakyReLU(negative_slope=0.1, inplace=True)\n   )\n   (105): Sequential(\n     (conv_105): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n   )\n   (106): Sequential(\n     (detection_106): DetectionLayer()\n   )\n ))"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks = read_cfg('detector/yolov3.cfg')\n",
    "create_modules(blocks)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T08:35:32.137356300Z",
     "start_time": "2023-10-18T08:35:31.244736300Z"
    }
   },
   "id": "a92a88dd7e818e9d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Darknet(nn.Module):\n",
    "    def __init__(self, filename):\n",
    "        super().__init__()\n",
    "        self.blocks = read_cfg(filename)\n",
    "        self.net, self.modules = create_modules(self.blocks)\n",
    "    \n",
    "    def forward(self, x, cuda):\n",
    "        blocks = self.blocks\n",
    "        output = {}\n",
    "        \n",
    "        write = False\n",
    "        detections = None\n",
    "        for i, block in enumerate(blocks):\n",
    "            block_type = block['type']\n",
    "            \n",
    "            if block_type == 'convolutional' or block_type == 'upsample':\n",
    "                x = self.modules[i](x)\n",
    "            elif block_type == 'route':\n",
    "                layers = list(map(int, block['layers']))\n",
    "                \n",
    "                if layers[0] > 0:\n",
    "                    layers[0] -= i\n",
    "                \n",
    "                if len(layers) == 1:\n",
    "                    x = output[i + layers[0]]\n",
    "                else:\n",
    "                    if layers[1] > 0:\n",
    "                        layers[1] -= i\n",
    "                    \n",
    "                    map1 = output[i + layers[0]]\n",
    "                    map2 = output[i + layers[1]]\n",
    "                    \n",
    "                    x = torch.cat((map1, map2), 1)\n",
    "            elif block_type == 'shortcut':\n",
    "                from_ = int(block['from'])\n",
    "                x = output[i - 1] + output[i + from_]\n",
    "            elif block_type == 'yolo':\n",
    "                anchors = self.modules[i][0].anchors\n",
    "                inp_dim = int(blocks[0]['height'])\n",
    "                num_classes = int(block['classes'])\n",
    "                \n",
    "                x = x.data\n",
    "                x = predict_transform(x, inp_dim, anchors, num_classes, cuda)\n",
    "                \n",
    "                if not write:\n",
    "                    detections = x\n",
    "                    write = True\n",
    "                else:\n",
    "                    detections = torch.cat((detections, x), 1)\n",
    "                \n",
    "        return detections"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f87015be586a667c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "96caea995a4a927e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
